{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9918ff09-5073-434b-b317-be4049bafee8",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3b4d7-c328-4997-8c9b-a2bf2975e60f",
   "metadata": {},
   "source": [
    "# Practice Project: Fruit Classification Using Transfer Learning \n",
    "**Estimated Time Needed:** 90 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1619cea-1651-46d2-9bf8-06549df5416b",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "In this lab, you will learn how to classify images of fruits using transfer learning with the pre-trained VGG16 model. Transfer learning enables leveraging a model trained on a large dataset (like ImageNet) and applying it to your dataset with fewer data and computational resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5851381b-2d02-42da-b477-dcf4a1c049e0",
   "metadata": {},
   "source": [
    "### Aim \n",
    "\n",
    "The aim is to build a fruit image classifier using transfer learning. You will fine-tune a pre-trained model on a custom dataset of fruit images to enable it to classify fruits effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ae5c2-74f2-4629-9232-4814a690da76",
   "metadata": {},
   "source": [
    "### Final output \n",
    "\n",
    "The final output will be a trained deep learning model capable of classifying various fruit images into their respective categories. You will also visualize the model's accuracy and predictions on sample test images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e6702-4533-4615-9bb7-6efc4a83509b",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "At the end of the project, you will be able to:\n",
    "- Set up and organize a complex fruit image dataset.\n",
    "- Use transfer learning with the VGG16 model.\n",
    "- Fine-tune a pre-trained model for your dataset.\n",
    "- Evaluate and interpret the model’s performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c0cf9-a062-475a-820b-0f2107f92f74",
   "metadata": {},
   "source": [
    "### Setup instructions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1dce0a-6c94-4450-ad6b-12c0da966267",
   "metadata": {},
   "source": [
    "#### Prerequisites \n",
    "\n",
    "- Basic knowledge of Python and Keras. \n",
    "\n",
    "- TensorFlow installed in your Python environment. \n",
    "\n",
    "- A data set of fruit images organized in subdirectories for each class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266cfcb1-ac21-4bb8-b3e3-8058fabeadec",
   "metadata": {},
   "source": [
    "#### code to suppress warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb594a8-98aa-446b-bd0c-204093ead771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.src.trainers.data_adapters.py_dataset_adapter\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.src.trainers.epoch_iterator\")\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress all warnings and info messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15b7e9-eb97-49b3-8ca0-6b27bed5219e",
   "metadata": {},
   "source": [
    "#### Required libraries \n",
    "\n",
    "Install the following libraries, if you haven't already: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9df3be-a63e-4772-8f6f-fa47e7e3dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (74.1.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (13.9.2)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.14.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy==1.14.1) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.5.2\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn==1.5.2) (3.5.0)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.1/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.7/11.0 MB 1.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.2/11.0 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.2/11.0 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.8/11.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.7/11.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.2/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.0\n",
      "    Uninstalling scikit-learn-1.6.0:\n",
      "      Successfully uninstalled scikit-learn-1.6.0\n",
      "Successfully installed scikit-learn-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.16.2\n",
    "!pip install matplotlib==3.9.2\n",
    "!pip install numpy==1.26.4\n",
    "!pip install scipy==1.14.1\n",
    "!pip install scikit-learn==1.5.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637016c3-9d2c-426b-a056-282bf667e0b4",
   "metadata": {},
   "source": [
    "### Data preparation \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d3e8eb5-227b-49fe-9d1c-4e9b2bcfb2a6",
   "metadata": {},
   "source": [
    "Directory structure \n",
    "\n",
    "Ensure that your data set is organized as follows: \n",
    "\n",
    "\n",
    "dataset/\n",
    "├── train/\n",
    "│   ├── Class1/\n",
    "│   ├── Class2/\n",
    "│   ├── Class3/\n",
    "│   └── (other classes...)\n",
    "├── val/\n",
    "│   ├── Class1/\n",
    "│   ├── Class2/\n",
    "│   ├── Class3/\n",
    "│   └── (other classes...)\n",
    "└── test/\n",
    "    ├── Class1/\n",
    "    ├── Class2/\n",
    "    ├── Class3/\n",
    "    └── (other classes...)\n",
    "\n",
    "\n",
    "Each subdirectory under train and val should contain images of the respective fruit category. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0c8ec-5106-4245-9afe-b0f0b1ecf459",
   "metadata": {},
   "source": [
    "### Tasks List\n",
    "To achieve the above objectives, you will complete the following tasks:\n",
    "\n",
    "- Task 1: Import necessary libraries and set dataset paths\n",
    "- Task 2: Set up data generators for training, validation, and testing with augmentation\n",
    "- Task 3: Define the VGG16-based model architecture with custom layers\n",
    "- Task 4: Compile the model with appropriate loss and optimizer\n",
    "- Task 5: Train the model with early stopping and learning rate scheduling\n",
    "- Task 6: Fine-tune the model by unfreezing specific layers in VGG16\n",
    "- Task 7: Evaluate the model on the test set and display accuracy\n",
    "- Task 8: Visualize training performance with accuracy and loss curves\n",
    "- Task 9: Test model predictions on sample images and visualize results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb020c-214a-4b53-bfa2-385a4d81cec6",
   "metadata": {},
   "source": [
    "<h2> Download the input data file </h2>\n",
    "\n",
    "Note: The dataset download may take up to 30 minutes depending on your internet connection. Please ensure a stable connection and wait until the download completes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfe9784-7971-4795-aadf-2519df427b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Le fichier spécifié est introuvable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Download the dataset if not already downloaded\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_zip):\n\u001b[1;32m---> 40\u001b[0m         \u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_zip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset already downloaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mdownload_dataset\u001b[1;34m(url, output_file)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download the dataset using wget in quiet mode.\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading the dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-q\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add `-q` for quiet mode\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Le fichier spécifié est introuvable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "# Define dataset URL and paths\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/4yIRGlIpNfKEGJYMhZV52g/fruits-360-original-size.zip\"\n",
    "local_zip = \"fruits-360-original-size.zip\"\n",
    "extract_dir = \"fruits-360-original-size\"\n",
    "\n",
    "def download_dataset(url, output_file):\n",
    "    \"\"\"Download the dataset using wget in quiet mode.\"\"\"\n",
    "    print(\"Downloading the dataset...\")\n",
    "    subprocess.run([\"wget\", \"-q\", \"-O\", output_file, url], check=True)  # Add `-q` for quiet mode\n",
    "    print(\"Download completed.\")\n",
    "\n",
    "def extract_zip_in_chunks(zip_file, extract_to, batch_size=2000):\n",
    "    \"\"\"\n",
    "    Extract a large zip file in chunks to avoid memory bottlenecks.\n",
    "    Processes a specified number of files (batch_size) at a time.\n",
    "    \"\"\"\n",
    "    print(\"Extracting the dataset in chunks...\")\n",
    "    os.makedirs(extract_to, exist_ok=True)  # Ensure the extraction directory exists\n",
    "    \n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        files = zip_ref.namelist()  # List all files in the archive\n",
    "        total_files = len(files)\n",
    "        \n",
    "        for i in range(0, total_files, batch_size):\n",
    "            batch = files[i:i+batch_size]\n",
    "            for file in batch:\n",
    "                zip_ref.extract(file, extract_to)  # Extract each file in the batch\n",
    "            print(f\"Extracted {min(i+batch_size, total_files)} of {total_files} files...\")\n",
    "    \n",
    "    print(f\"Dataset successfully extracted to '{extract_to}'.\")\n",
    "\n",
    "# Main script execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Download the dataset if not already downloaded\n",
    "    if not os.path.exists(local_zip):\n",
    "        download_dataset(url, local_zip)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "    \n",
    "    # Extract the dataset if not already extracted\n",
    "    if not os.path.exists(extract_dir):\n",
    "        extract_zip_in_chunks(local_zip, extract_dir)\n",
    "    else:\n",
    "        print(\"Dataset already extracted.\")\n",
    "    \n",
    "    # Optional cleanup of the zip file\n",
    "    if os.path.exists(local_zip):\n",
    "        os.remove(local_zip)\n",
    "        print(f\"Cleaned up zip file: {local_zip}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f0590-4efd-4f79-be45-220c6345b680",
   "metadata": {},
   "source": [
    "<h5>Note: If you see warnings related to GPU (e.g., CUDA or cuDNN), it means the system is running on the CPU. Training may take longer.</h5>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380b61e-585b-4fa1-a40b-bbd1e584809a",
   "metadata": {},
   "source": [
    "<h3> Task 1: Import necessary libraries and set dataset paths </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be00f52-f2d5-457e-85f0-78ec2ff3a7f7",
   "metadata": {},
   "source": [
    "**Explanation:** This task involves importing essential libraries and setting up the paths for the dataset directories (train, val, and test). These libraries are necessary for data handling, model building, and performance evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "423d558d-b0ca-492c-b582-2760573b0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Set dataset paths\n",
    "train_dir = 'fruits-360-original-size/fruits-360-original-size/Training'\n",
    "val_dir = 'fruits-360-original-size/fruits-360-original-size/Validation'\n",
    "test_dir = 'fruits-360-original-size/fruits-360-original-size/Test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd131b-fa77-4116-8e30-2f47dcf273c0",
   "metadata": {},
   "source": [
    "### Library Explanations:\n",
    "- `ImageDataGenerator:` For loading images and applying data augmentation.\n",
    "- `VGG16:` Pre-trained model used for transfer learning.\n",
    "- `Sequential:` For building a sequential model.\n",
    "- `Dense, Flatten, Dropout, BatchNormalization:` Layers to customize the model architecture.\n",
    "- `ReduceLROnPlateau, EarlyStopping:` Callbacks for optimizing training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b903b9-83ed-4a28-abe6-02766cbce88a",
   "metadata": {},
   "source": [
    "<h3> Task 2: Set up data generators for training, validation, and testing with augmentation </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07984a58-9e44-466e-a8c3-4c62ef55b5e9",
   "metadata": {},
   "source": [
    "**Explanation:** Data generators load images from directories, rescale them, and apply augmentation on the training set to help the model generalize better. Validation and test sets are only rescaled (no augmentation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77738378-1f08-4461-80e7-1eeeccbb0268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'fruits-360-original-size/fruits-360-original-size/Training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load images from directories\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     25\u001b[0m     val_dir,\n\u001b[0;32m     26\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m     27\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m     28\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     32\u001b[0m     test_dir,\n\u001b[0;32m     33\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m     34\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m     35\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'fruits-360-original-size/fruits-360-original-size/Training'"
     ]
    }
   ],
   "source": [
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc921e6-603b-4fa6-8e7b-cc5610d7de9c",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- `train_datagen:` Applies rescaling and augmentation (e.g., rotation, zoom) to make the model more robust.\n",
    "- `val_datagen and test_datagen:` Only rescale images for validation/testing.\n",
    "- `flow_from_directory:` Loads images from specified folders into batches for training/validation/testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb76aba-b0ba-4431-9a58-26463bb26221",
   "metadata": {},
   "source": [
    "<h3>Task 3: Define the VGG16-based model architecture with custom layers</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceddb79-6983-4ecd-b660-7a0a244860c3",
   "metadata": {},
   "source": [
    "**Explanation:** This task involves loading the pre-trained VGG16 model (excluding the top layers) and adding custom layers to adapt it to the fruit classification task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7780c905-9d1f-4109-9198-b5ce94d9063d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m      9\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     13\u001b[0m     base_model,\n\u001b[0;32m     14\u001b[0m     GlobalAveragePooling2D(),\n\u001b[0;32m     15\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     16\u001b[0m     BatchNormalization(),\n\u001b[0;32m     17\u001b[0m     Dropout(\u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m---> 18\u001b[0m     Dense(\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241m.\u001b[39mnum_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
    "\n",
    "# Load VGG16 with pre-trained weights\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7020e-add4-40f4-9b41-2334f3e4f6aa",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- `base_model:` Loads VGG16, excluding its dense layers (`include_top=False`).\n",
    "- `for layer in base_model.layers:` Freezes VGG16 layers to retain pre-trained weights.\n",
    "- Custom layers: Flatten the output, then add dense layers with regularization (Dropout) and normalization (BatchNormalization) to enhance learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87270d53-582e-4ff3-ab9f-664dab00fe7c",
   "metadata": {},
   "source": [
    "<h3>Task 4: Compile the model with appropriate loss and optimizer</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4f37c-3797-4d82-afa7-85dc0a11aae9",
   "metadata": {},
   "source": [
    "**Explanation:** Compile the model to specify the loss function, optimizer, and evaluation metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20190e52-9cf2-40ee-a7ba-ca6052868e75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      2\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d6928-1e07-4969-a5ee-bffaae066517",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- `categorical_crossentropy:` Used because this is a multi-class classification task.\n",
    "- `adam:` Adaptive learning rate optimizer that helps in faster convergence.\n",
    "- `metrics=['accuracy']:` Tracks model accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a94bf-9a36-420c-99b3-4cbf15a32c71",
   "metadata": {},
   "source": [
    "<h3>Task 5: Train the model with early stopping and learning rate scheduling</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5363d80e-175f-4edc-8515-0449aef98509",
   "metadata": {},
   "source": [
    "**Explanation:** Train the model, using callbacks to monitor the validation loss and adjust the learning rate or stop early to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cd9223-9a66-4d94-8df2-72e289d9cb1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m \n\u001b[0;32m     13\u001b[0m validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     16\u001b[0m     train_generator,\n\u001b[0;32m     17\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     18\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator,  \n\u001b[0;32m     19\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,  \n\u001b[0;32m     20\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,  \n\u001b[0;32m     21\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lr_scheduler, early_stopping]\n\u001b[0;32m     22\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Enable mixed precision (if on GPU)\n",
    "set_global_policy('float32')\n",
    "\n",
    "steps_per_epoch = 50 \n",
    "validation_steps = 25\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,  \n",
    "    steps_per_epoch=steps_per_epoch,  \n",
    "    validation_steps=validation_steps,  \n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42745bd0-9e7c-4dda-aac2-6b93f6afcd5c",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- `ReduceLROnPlateau`: Reduces learning rate when validation loss plateaus, allowing better optimization.\n",
    "- `EarlyStopping`: Stops training when validation loss no longer improves, preventing overfitting.\n",
    "- `model.fit`: Trains the model on the `train_generator` and evaluates on `val_generator` each epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6c41e-6947-47bc-96b1-ed28a993b03e",
   "metadata": {},
   "source": [
    "<h3>Task 6: Fine-tune the model by unfreezing specific layers in VGG16</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e152a-91ad-47f7-b6f0-a1504212c811",
   "metadata": {},
   "source": [
    "**Explanation:** Fine-tune by unfreezing a few layers in the VGG16 base model to allow learning on fruit-specific features.\n",
    "\n",
    "**Note**: Fine-tuning may take excess time on a CPU-based machine. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66cb9666-8247-431c-b11c-0b91ad05a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model has 19 layers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m         layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Re-compile the model with a faster optimizer\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     20\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m),   \u001b[38;5;66;03m# Higher learning rate for faster convergence\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Continue training with fewer steps per epoch\u001b[39;00m\n\u001b[0;32m     26\u001b[0m history_fine \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     27\u001b[0m     train_generator,\n\u001b[0;32m     28\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lr_scheduler, early_stopping]\n\u001b[0;32m     33\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf  # Import TensorFlow for accessing tf.keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Check the number of layers in the base model\n",
    "num_layers = len(base_model.layers)\n",
    "print(f\"The base model has {num_layers} layers.\")\n",
    "\n",
    "# Unfreeze the last 5 layers for fine-tuning\n",
    "for layer in base_model.layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Freeze BatchNorm layers to speed up fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Re-compile the model with a faster optimizer\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),   # Higher learning rate for faster convergence\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training with fewer steps per epoch\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  # Reduced steps per epoch\n",
    "    validation_steps=validation_steps,  # Reduced validation steps\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38698d77-fb46-4238-8066-e12ff8266cd6",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- `for layer in base_model.layers[-5:]`: Unfreezes the last 5 layers to allow fine-tuning.\n",
    "-  Unfreezing fewer layers is faster and prevents overfitting on small datasets.\n",
    "- `RMSprop(learning_rate=1e-5)`: Optimizer with a lower learning rate to fine-tune carefully without drastic weight changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379743f4-229e-4136-81dd-7477aef6b084",
   "metadata": {},
   "source": [
    "<h3>Task 7: Evaluate the model on the test set and display accuracy</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626609d-62dc-4171-a05a-3190c96c9445",
   "metadata": {},
   "source": [
    "**Explanation**: Evaluates the final model on unseen test data to gauge its generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89cc85e6-1ae0-458c-aa83-8e6e07c7a43d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_generator, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=50)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1da6a9-6d9b-4e0b-b390-778767c842d4",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- `model.evaluate(test_generator)`: Evaluates the model on the test set and prints accuracy, giving a final measure of model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0d4ee-2840-4288-862b-f0dc92988415",
   "metadata": {},
   "source": [
    "<h3> Task 8: Visualize training performance with accuracy and loss curves </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97ea10-cd69-4824-93a1-7d09b3cb2b56",
   "metadata": {},
   "source": [
    "**Explanation**: Plots the training and validation accuracy and loss to understand the model’s learning progress.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0196ea39-f769-484d-8d21-cc64dc73ea32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot accuracy and loss curves\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_fine\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tuned Training Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot accuracy and loss curves\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(history_fine.history['accuracy'], label='Fine-tuned Training Accuracy')\n",
    "plt.plot(history_fine.history['val_accuracy'], label='Fine-tuned Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history_fine.history['loss'], label='Fine-tuned Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Fine-tuned Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af4921-4edd-470b-84d4-f823ce147352",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- `plt.plot`: Plots the accuracy and loss for training and validation over epochs.\n",
    "  \n",
    "- Visual comparison shows if the model is overfitting, underfitting, or learning effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a0869-5a71-4ece-9d31-c890c62b66ed",
   "metadata": {},
   "source": [
    "<h3>Task 9: Test model predictions on sample images and visualize results</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f32300-c0cd-40f8-8b7a-d83e1dc50a54",
   "metadata": {},
   "source": [
    "**Explanation:** Makes predictions on a few test images and displays them with the model's predicted class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f4cb701-3835-4eae-b87b-dac77317f782",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Retrieve class index mapping from the training generator\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m class_index_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Index Mapping:\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_index_mapping)  \u001b[38;5;66;03m# Debugging: Check the mapping\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Define a list of image paths without hardcoded labels\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize counters for actual and predicted classes\n",
    "actual_count = Counter()\n",
    "predicted_count = Counter()\n",
    "\n",
    "# Function to get class name from predicted index\n",
    "def get_class_name_from_index(predicted_index, class_index_mapping):\n",
    "    \"\"\"Convert predicted index to class name.\"\"\"\n",
    "    for class_name, index in class_index_mapping.items():\n",
    "        if index == predicted_index:\n",
    "            return class_name\n",
    "    return \"Unknown\"  # Default if index is not found\n",
    "\n",
    "# Define the function for visualization\n",
    "def visualize_prediction_with_actual(img_path, class_index_mapping):\n",
    "    # Extract the true label dynamically from the directory structure\n",
    "    class_name = os.path.basename(os.path.dirname(img_path))  # Extract folder name (class)\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = load_img(img_path, target_size=(64, 64)) \n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict the class\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_index = np.argmax(prediction, axis=-1)[0]\n",
    "    predicted_class_name = get_class_name_from_index(predicted_index, class_index_mapping)\n",
    "\n",
    "    # Update the counters\n",
    "    actual_count[class_name] += 1\n",
    "    predicted_count[predicted_class_name] += 1\n",
    "\n",
    "    # Visualize the image with predictions\n",
    "    plt.figure(figsize=(2, 2), dpi=100)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Actual: {class_name}, Predicted: {predicted_class_name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Retrieve class index mapping from the training generator\n",
    "class_index_mapping = train_generator.class_indices\n",
    "print(\"Class Index Mapping:\", class_index_mapping)  # Debugging: Check the mapping\n",
    "\n",
    "# Define a list of image paths without hardcoded labels\n",
    "sample_images = [\n",
    "    'fruits-360-original-size/fruits-360-original-size/Test/apple_braeburn_1/r0_11.jpg',\n",
    "    'fruits-360-original-size/fruits-360-original-size/Test/pear_1/r0_103.jpg',\n",
    "    'fruits-360-original-size/fruits-360-original-size/Test/cucumber_3/r0_103.jpg',\n",
    "]\n",
    "\n",
    "# Run the predictions and visualization\n",
    "for img_path in sample_images:\n",
    "    visualize_prediction_with_actual(img_path, class_index_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f9988-4cad-42f8-9c67-8af75cbb30dd",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- `visualize_prediction`: Loads an image, preprocesses it, predicts its class, and displays it.\n",
    "  \n",
    "- `model.predict(img_array)`: Uses the trained model to make predictions on unseen images.\n",
    "\n",
    "##### If there is an incorrect prediction during testing, the following factors could contribute to the misclassification:\n",
    "\n",
    "Class Similarity: Visually similar fruit classes (e.g., apple types) can confuse the model.\n",
    "\n",
    "Insufficient Data: Imbalanced datasets with fewer samples for certain classes may cause underfitting.\n",
    "\n",
    "Limited Training: Fine-tuning fewer layers might not capture sufficient class-specific features.\n",
    "\n",
    "Data Augmentation Impact: Aggressive augmentations may distort key features, reducing accuracy for specific images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b0274-39f6-4207-abb7-5d745b078b47",
   "metadata": {},
   "source": [
    "### Conclusion \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84cd89-9b49-4059-af10-9fcb9fa647f2",
   "metadata": {},
   "source": [
    "In this lab, you implemented a fruit classification model using transfer learning with VGG16. By fine-tuning and using data augmentation, you developed a robust classifier that can recognize different fruits. This lab demonstrated the efficiency of transfer learning in achieving high accuracy with minimal training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1a2f1-0d50-4bd1-9c8e-4ef6592ac9f4",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "Skills Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc8f2a-9f74-422f-893b-98f0a88d8597",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "prev_pub_hash": "a5004bd4f77c95c33c59934b2ac2d6d3a45d1dd6869bb6376c595cfaf2a2704d"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
